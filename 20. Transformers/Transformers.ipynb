{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformers.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXyWjzoODgpv"
      },
      "source": [
        "### **INITIALIZATION:**\n",
        "- I use these three lines of code on top of my each notebooks because it will help to prevent any problems while reloading the same project. And the third line of code helps to make visualization within the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZq69_01CoSW"
      },
      "source": [
        "#@ INITIALIZATION: \n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GZB8tEyDn70"
      },
      "source": [
        "**LIBRARIES AND DEPENDENCIES:**\n",
        "- I have downloaded all the libraries and dependencies required for the project in one particular cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAUugqiDDlh-"
      },
      "source": [
        "#@ INSTALLING DEPENDENCIES: UNCOMMENT BELOW: \n",
        "# !pip install -Uqq fastbook\n",
        "# import fastbook\n",
        "# fastbook.setup_book()\n",
        "# !pip install -Uq transformers"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AE45oW7HD8Rv"
      },
      "source": [
        "#@ DOWNLOADING LIBRARIES AND DEPENDENCIES: \n",
        "from fastai.basics import *\n",
        "from fastai.callback.all import *\n",
        "from fastai.text.all import *\n",
        "\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
        "\n",
        "#@ IGNORING WARNINGS: \n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bmqxQ8UFVwX"
      },
      "source": [
        "### **GPT2 MODEL:**\n",
        "- There are several versions of **GPT2 Model** : [**Transformers Documentation**](https://huggingface.co/transformers/pretrained_models.html). I will inspect the **Tokenizer** and **Model**. The **Tokenizers** in **HuggingFace** usually do the tokenization and numericalization in one step. The **Model** can generate predictions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp_3_xqrE-nU"
      },
      "source": [
        "#@ LOADING PRETRAINED MODEL: \n",
        "pretrained_weights = \"gpt2\"                                         # Initialization. \n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(pretrained_weights)   # Initializing Tokenizer. \n",
        "model = GPT2LMHeadModel.from_pretrained(pretrained_weights)         # Initializing Pretrained Model. "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "rlTnpcD5GtvE",
        "outputId": "6f621810-d87e-42a6-ab27-8a31cc6fc83b"
      },
      "source": [
        "#@ INSPECTING TOKENIZER: \n",
        "ids = tokenizer.encode(\"Hello there! How are you?\")                 # Implementation of Tokenizer. \n",
        "print(ids)                                                          # Inspection. \n",
        "tokenizer.decode(ids)                                               # Getting Text. "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15496, 612, 0, 1374, 389, 345, 30]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hello there! How are you?'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmQ_6IiPH_oE",
        "outputId": "4f8849e9-bc49-4d89-d0e6-924f92369636"
      },
      "source": [
        "#@ INSPECTING PREDICTIONS: \n",
        "t = torch.LongTensor(ids)[None]                                     # Initializing 1D Tensor. \n",
        "preds = model.generate(t)                                           # Generating Predictions. \n",
        "preds.shape, preds[0]                                               # Inspection. "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 20]),\n",
              " tensor([15496,   612,     0,  1374,   389,   345,    30,   198,   198,    40,  1101,   257,  1310,  1643, 10032,   286,   262,  6678,  3404,    13]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VmsqfGC4JNKk",
        "outputId": "53315785-2bfd-4b2f-b330-f0a05d77decb"
      },
      "source": [
        "#@ INSPECTING PREDICTIONS: \n",
        "tokenizer.decode(preds[0].numpy())                                  # Inspection. "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Hello there! How are you?\\n\\nI'm a little bit tired of the usual stuff.\""
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toGrkMWiKjvw"
      },
      "source": [
        "### **PREPARING DATA:**\n",
        "- I will use **wikitext-2** dataset here. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krb7mXedKMfp",
        "outputId": "6edf5c82-f70a-4862-e08e-f4eefae30a6e"
      },
      "source": [
        "#@ GETTING THE DATASET: \n",
        "path = untar_data(URLs.WIKITEXT_TINY)                   # Initializing Path to Dataset. \n",
        "path.ls()                                               # Inspection.                           "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('/root/.fastai/data/wikitext-2/test.csv'),Path('/root/.fastai/data/wikitext-2/train.csv')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "J-Pjdmb3LmnE",
        "outputId": "2ca5229d-8f91-4b8b-c20e-453e36608be6"
      },
      "source": [
        "#@ LOADING THE DATASET: \n",
        "df_train = pd.read_csv(path/\"train.csv\", header=None)   # Reading the Data.\n",
        "df_valid = pd.read_csv(path/\"test.csv\", header=None)    # Reading the Data. \n",
        "df_train.head(2)                                        # Inspecting the Data. "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\n = 2013 – 14 York City F.C. season = \\n \\n The 2013 – 14 season was the &lt;unk&gt; season of competitive association football and 77th season in the Football League played by York City Football Club , a professional football club based in York , North Yorkshire , England . Their 17th @-@ place finish in 2012 – 13 meant it was their second consecutive season in League Two . The season ran from 1 July 2013 to 30 June 2014 . \\n Nigel Worthington , starting his first full season as York manager , made eight permanent summer signings . By the turn of the year York were only above the relegation z...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\n = Big Boy ( song ) = \\n \\n \" Big Boy \" &lt;unk&gt; \" I 'm A Big Boy Now \" was the first single ever recorded by the Jackson 5 , which was released by Steeltown Records in January 1968 . The group played instruments on many of their Steeltown compositions , including \" Big Boy \" . The song was neither a critical nor commercial success , but the Jackson family were delighted with the outcome nonetheless . \\n The Jackson 5 would release a second single with Steeltown Records before moving to Motown Records . The group 's recordings at Steeltown Records were thought to be lost , but they were re...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         0\n",
              "0   \\n = 2013 – 14 York City F.C. season = \\n \\n The 2013 – 14 season was the <unk> season of competitive association football and 77th season in the Football League played by York City Football Club , a professional football club based in York , North Yorkshire , England . Their 17th @-@ place finish in 2012 – 13 meant it was their second consecutive season in League Two . The season ran from 1 July 2013 to 30 June 2014 . \\n Nigel Worthington , starting his first full season as York manager , made eight permanent summer signings . By the turn of the year York were only above the relegation z...\n",
              "1   \\n = Big Boy ( song ) = \\n \\n \" Big Boy \" <unk> \" I 'm A Big Boy Now \" was the first single ever recorded by the Jackson 5 , which was released by Steeltown Records in January 1968 . The group played instruments on many of their Steeltown compositions , including \" Big Boy \" . The song was neither a critical nor commercial success , but the Jackson family were delighted with the outcome nonetheless . \\n The Jackson 5 would release a second single with Steeltown Records before moving to Motown Records . The group 's recordings at Steeltown Records were thought to be lost , but they were re..."
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZyXakLvMPAl"
      },
      "source": [
        "#@ LOADING THE DATA:\n",
        "all_texts = np.concatenate([df_train[0].values, \n",
        "                            df_valid[0].values])        # Initializing Concatenation. "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNuj9jifYzC_"
      },
      "source": [
        "### **TRANSFORMERS TOKENIZER:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ow-e_esmZamX"
      },
      "source": [
        "**TRANSFORM METHOD:**  \n",
        "**Fastai Transform** is defined as:     \n",
        "- an **encodes** method that is applied when **transform** is called. \n",
        "- a **decodes** method that is applied when **decode** method of transform is called. \n",
        "- a **setups** method that sets inner state of **Transform**. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD2nc3FeYgld"
      },
      "source": [
        "#@ DEFINING TRANSFORMERS TOKENIZER: \n",
        "class TransformersTokenizer(Transform):                     # Defining Tokenizer. \n",
        "    def __init__(self, tokenizer):                          # Initializing Constructor Function. \n",
        "        self.tokenizer = tokenizer                          # Initializing Tokenizer. \n",
        "    \n",
        "    def encodes(self, x):                                   # Initializing Encode Method. \n",
        "        toks = self.tokenizer.tokenize(x)                   # Initializing Tokenizer. \n",
        "        return tensor(\n",
        "            self.tokenizer.convert_tokens_to_ids(toks))     # Generating IDs. \n",
        "    \n",
        "    def decodes(self, x):                                   # Initializing Decode Method. \n",
        "        return TitledStr(\n",
        "            self.tokenizer.decode(x.cpu().numpy()))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZffqEbxaciHT",
        "outputId": "77999052-f6c8-427f-d145-733bebe3e44a"
      },
      "source": [
        "#@ IMPLEMENTATION OF TRANSFORM METHOD: \n",
        "splits = [range_of(df_train), \n",
        "          list(range(len(df_train), len(all_texts)))]       # Initialization. \n",
        "tls = TfmdLists(all_texts,TransformersTokenizer(tokenizer), \n",
        "                splits=splits, dl_type=LMDataLoader)        # Initializing Transformed DataLoader. \n",
        "\n",
        "#@ INSPECTING TRANSFORMED DATALOADER: \n",
        "print(tls.train[0], tls.valid[0])\n",
        "print(tls.tfms(tls.train.items[0]).shape, \n",
        "      tls.tfms(tls.valid.items[0]).shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([220, 198, 796,  ..., 198, 220, 198]) tensor([220, 198, 796,  ..., 198, 220, 198])\n",
            "torch.Size([4576]) torch.Size([1485])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oizPdOXFeQZj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}