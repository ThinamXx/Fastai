{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk5SHfqIc6Ey"
      },
      "source": [
        "### **INITIALIZATION:**\n",
        "- I use these three lines of code on top of my each notebooks because it will help to prevent any problems while reloading the same project. And the third line of code helps to make visualization within the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9K2einKadKr"
      },
      "source": [
        "#@ INITIALIZATION: \n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTFZaPENdHTs"
      },
      "source": [
        "**LIBRARIES AND DEPENDENCIES:**\n",
        "- I have downloaded all the libraries and dependencies required for the project in one particular cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZDkvIrydDtY"
      },
      "source": [
        "#@ INSTALLING DEPENDENCIES: UNCOMMENT BELOW: \n",
        "# !pip install -Uqq fastbook\n",
        "# import fastbook\n",
        "# fastbook.setup_book()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTIdUUtEdOah"
      },
      "source": [
        "#@ DOWNLOADING LIBRARIES AND DEPENDENCIES: \n",
        "from fastbook import *                              # Getting all the Libraries. \n",
        "from fastai.callback.fp16 import *\n",
        "from fastai.text.all import *                       # Getting all the Libraries.\n",
        "from IPython.display import display, HTML"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAY-kcjCd-Tz"
      },
      "source": [
        "### **GETTING THE DATASET:**\n",
        "- I will get the **IMDB Dataset** here. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "iv-s-9D1dsia",
        "outputId": "1cbe2f83-4356-460c-c0d9-ea26f43b7c50"
      },
      "source": [
        "#@ GETTING THE DATASET: \n",
        "path = untar_data(URLs.IMDB)                       # Getting Path to the Dataset. \n",
        "path.ls()                                          # Inspecting the Path. "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#7) [Path('/root/.fastai/data/imdb/tmp_lm'),Path('/root/.fastai/data/imdb/README'),Path('/root/.fastai/data/imdb/tmp_clas'),Path('/root/.fastai/data/imdb/unsup'),Path('/root/.fastai/data/imdb/imdb.vocab'),Path('/root/.fastai/data/imdb/train'),Path('/root/.fastai/data/imdb/test')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dBavrB_6e_Of",
        "outputId": "c1b02913-628c-4fbb-977e-041ae294dd8e"
      },
      "source": [
        "#@ GETTING TEXT FILES: \n",
        "files = get_text_files(path, folders=[\"train\", \"test\", \"unsup\"])        # Getting Text Files. \n",
        "txt = files[0].open().read()                                            # Getting a Text. \n",
        "txt[:75]                                                                # Inspecting Text. "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"*** May contain spoilers*** Wow. This movie is really bad. It's so bad that\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kG832kuRgXeo"
      },
      "source": [
        "### **WORD TOKENIZATION:**\n",
        "- **Word Tokenization** splits a sentence on spaces as well as applying language specific rules to try to separate parts of meaning even when there are no spaces. Generally punctuation marks are also split into separate tokens. **Token** is a element of a list created by the **Tokenization** process which could be a word, a part of a word or subword or a single character. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yx1lsBcYgQ9K",
        "outputId": "3ffc2d92-d74b-4c3c-aebe-fcbbcf26c50e"
      },
      "source": [
        "#@ INITIALIZING WORD TOKENIZATION: \n",
        "spacy = WordTokenizer()                                  # Initializing Tokenizer. \n",
        "toks = first(spacy([txt]))                               # Getting Tokens of Words. \n",
        "print(coll_repr(toks, 30))                               # Inspecting Tokens. "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(#477) ['*','*','*','May','contain','spoilers','*','*','*','Wow','.','This','movie','is','really','bad','.','It',\"'s\",'so','bad','that','the','first','word','of','the','title','is','misspelled'...]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ti9Hi_uriKxe",
        "outputId": "04d5ba6f-02e3-427c-9615-82e14790c045"
      },
      "source": [
        "#@ INSPECTING TOKENIZATION: EXAMPLE:\n",
        "first(spacy(['The U.S. dollar $1 is $1.00.']))           # Inspecting Tokens. "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#9) ['The','U.S.','dollar','$','1','is','$','1.00','.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liWRboFJi84p",
        "outputId": "f4056fd1-1c11-4cd3-a65a-69f01b46dab8"
      },
      "source": [
        "#@ INITIALIZING WORD TOKENIZATION WITH FASTAI: \n",
        "tkn = Tokenizer(spacy)                                   # Initializing Tokenizer. \n",
        "print(coll_repr(tkn(txt), 31))                           # Inspecting Tokens. "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(#505) ['xxbos','xxrep','3','*','xxmaj','may','contain','spoilers','xxrep','3','*','xxmaj','wow','.','xxmaj','this','movie','is','really','bad','.','xxmaj','it',\"'s\",'so','bad','that','the','first','word','of'...]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsVt5tA8P1hU"
      },
      "source": [
        "**Note:**\n",
        "- **xxbos** : Indicates the beginning of a text. \n",
        "- **xxmaj** : Indicates the next word begins with a capital. \n",
        "- **xxunk** : Indicates the next word is unknown.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "X-GgI67Ajr-K",
        "outputId": "c0bfa4d1-7286-469c-cb99-2eb5fbf29d79"
      },
      "source": [
        "#@ INSPECTING TOKENIZATION: EXAMPLE:\n",
        "coll_repr(tkn('&copy; Fast.ai www.fast.ai/INDEX'), 30)   # Inspecting Tokens. "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"(#11) ['xxbos','©','xxmaj','fast.ai','xxrep','3','w','.fast.ai','/','xxup','index']\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8clYuvALmBg"
      },
      "source": [
        "### **SUBWORD TOKENIZATION:**\n",
        "- **Word Tokenization** relies on an assumption that spaces provide a useful separation of components of meaning in a sentence which is not always appropriate. Languages such as Chinese and Japanese don't use spaces and in such cases **Subword Tokenization** generally plays the best role. **Subword Tokenization** splits words into smaller parts based on the most commonly occurring sub strings. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AO-mr3aLm2QB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "201efc06-85f7-4ed2-d7dc-17c7a05498d7"
      },
      "source": [
        "#@ INITIALIZING SUBWORD TOKENIZATION: EXAMPLE:\n",
        "txts = L(o.open().read() for o in files[:2000])                # Getting List of Reviews. \n",
        "\n",
        "#@ INITIALIZING SUBWORD TOKENIZER: \n",
        "def subword(sz):                                               # Defining Function.      \n",
        "    sp = SubwordTokenizer(vocab_sz=sz)                         # Initializing Subword Tokenizer. \n",
        "    sp.setup(txts)                                             # Getting Sequence of Characters. \n",
        "    return \" \".join(first(sp([txt]))[:40])                     # Inspecting the Vocab. \n",
        "\n",
        "#@ IMPLEMENTATION: \n",
        "subword(1000)                                                  # Inspecting Subword Tokenization. "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"▁ *** ▁Ma y ▁con t ain ▁sp o il ers *** ▁W ow . ▁This ▁movie ▁is ▁really ▁bad . ▁It ' s ▁so ▁bad ▁that ▁the ▁first ▁word ▁of ▁the ▁title ▁is ▁mis s p ell ed ▁(\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWSi_eQzQcxL"
      },
      "source": [
        "**Notes:**\n",
        "- Here **setup** is a special fastai method that is called automatically in usual data processing pipelines which reads the documents and find the common sequences of characters to create the vocab. Similarly [**L**](https://fastcore.fast.ai/#L) is also referred as superpowered list. The special character '_' represents a space character in the original text. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "MpSPYDjIQbVP",
        "outputId": "22405df2-e815-4244-b450-54147e57c018"
      },
      "source": [
        "#@ IMPLEMENTATION OF SUBWORD TOKENIZATION: \n",
        "subword(200)                                                  # Inspecting Vocab. \n",
        "subword(10000)                                                # Inspecting Vocab. "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"▁*** ▁May ▁contain ▁spoiler s *** ▁Wow . ▁This ▁movie ▁is ▁really ▁bad . ▁It ' s ▁so ▁bad ▁that ▁the ▁first ▁word ▁of ▁the ▁title ▁is ▁miss pell ed ▁( I ' d ▁be ▁willing ▁to ▁allow ▁for ▁the\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTxPsa_RT-oU"
      },
      "source": [
        "**Note:**\n",
        "- A larger vocab means fewer tokens per sentence which means faster training, less memory, and less state for the model to remember but it means larger embedding matrices and require more data to learn. **Subword Tokenization** provides a way to easily scale between character tokenization i.e. using a small subword vocab and word tokenization i.e using a large subword vocab and handles every human language without needing language specific algorithms to be developed. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9scF0s-DVQjf"
      },
      "source": [
        "### **NUMERICALIZATION:**\n",
        "- **Numericalization** is the process of mapping tokens to integers. It involves making a list of all possible levels of that categorical variable or the vocab and replacing each level with its index in the vocab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vV8wXsyFTb42",
        "outputId": "b29b116f-5dbb-4df5-da13-4c2746008ca1"
      },
      "source": [
        "#@ INITIALIZING TOKENS: \n",
        "toks = tkn(txt)                                              # Getting Tokens. \n",
        "print(coll_repr(tkn(txt), 31))                               # Inspecting Tokens. "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(#505) ['xxbos','xxrep','3','*','xxmaj','may','contain','spoilers','xxrep','3','*','xxmaj','wow','.','xxmaj','this','movie','is','really','bad','.','xxmaj','it',\"'s\",'so','bad','that','the','first','word','of'...]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GORafHQXscv",
        "outputId": "b77608aa-f27f-427a-dc77-cdaacc616dc1"
      },
      "source": [
        "#@ INITIALIZING TOKENS: \n",
        "toks200 = txts[:200].map(tkn)                                # Getting Tokens. \n",
        "toks200[0]                                                   # Inspecting Tokens. "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#505) ['xxbos','xxrep','3','*','xxmaj','may','contain','spoilers','xxrep','3'...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ta9px3-xZfNs",
        "outputId": "8c665848-99d8-4c62-ac58-7c6c079b95ad"
      },
      "source": [
        "#@ NUMERICALIZATION USING FASTAI: \n",
        "num = Numericalize()                                         # Initializing Numericalization. \n",
        "num.setup(toks200)                                           # Getting Integers. \n",
        "coll_repr(num.vocab, 20)                                     # Inspecting Vocabulary. "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"(#2216) ['xxunk','xxpad','xxbos','xxeos','xxfld','xxrep','xxwrep','xxup','xxmaj','the',',','.','and','a','of','to','is','in','it','that'...]\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tt8fU-YNfROJ",
        "outputId": "edc85aa7-99b3-4ab2-adb0-6c547497020a"
      },
      "source": [
        "#@ INITIALIZING NUMERICALIZATION: \n",
        "nums = num(toks)[:20]; nums                                  # Inspection. \n",
        "\" \".join(num.vocab[o] for o in nums)                         # Getting Original Text. "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'xxbos xxrep 3 * xxmaj may xxunk xxunk xxrep 3 * xxmaj xxunk . xxmaj this movie is really bad'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_ZJYk8jVowc"
      },
      "source": [
        "### **CREATING BATCHES FOR LANGUAGE MODEL:**\n",
        "- At every epoch I will shuffle the collection of documents and concatenate them into a stream of tokens and cut that stream into a batch of fixedsize consecutive ministreams. The model will then read the ministreams in order. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thsG0lr0Xq1w",
        "outputId": "ba27f473-1525-4485-d877-876b37b89f96"
      },
      "source": [
        "#@ CREATING BATCHES FOR LANGUAGE MODEL: \n",
        "nums200 = toks200.map(num)                                   # Initializing Numericalization. \n",
        "dl = LMDataLoader(nums200)                                   # Creating Language Model Data Loaders. \n",
        "\n",
        "#@ INSPECTING FIRST BATCH: \n",
        "x, y = first(dl)                                             # Getting First Batch of Data. \n",
        "x.shape, y.shape                                             # Inspecting Shape of Data. "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 72]), torch.Size([64, 72]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nYkjwoIMZEIQ",
        "outputId": "ce2ceab2-9f62-4dfa-b259-bd7fab713b4b"
      },
      "source": [
        "#@ INSPECTING THE DATA: \n",
        "\" \".join(num.vocab[o] for o in x[0][:20])                    # Inspecting Independent Variable. "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'xxbos xxrep 3 * xxmaj may xxunk xxunk xxrep 3 * xxmaj xxunk . xxmaj this movie is really bad'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jnoIOJ2oZsNJ",
        "outputId": "9c7950ae-356a-4a07-c1a5-44c5dfb0b86f"
      },
      "source": [
        "#@ INSPECTING THE DATA: \n",
        "\" \".join(num.vocab[o] for o in y[0][:20])                    # Inspecting Dependent Variable. "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'xxrep 3 * xxmaj may xxunk xxunk xxrep 3 * xxmaj xxunk . xxmaj this movie is really bad .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYAR0Mx9a9DY"
      },
      "source": [
        "### **TRAINING A TEXT CLASSIFIER:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDYi_GrzfvqP"
      },
      "source": [
        "**LANGUAGE MODEL USING DATABLOCK:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "NjRlvq8KbbXF",
        "outputId": "c8ea7609-7f4d-45c8-c9e6-26469f6e7b83"
      },
      "source": [
        "#@ CREATING LANGUAGE MODEL USING DATABLOCK: \n",
        "get_imdb = partial(get_text_files, folders=[\"train\", \"test\", \"unsup\"])    # Getting Text Files. \n",
        "db = DataBlock(blocks=TextBlock.from_folder(path, is_lm=True),            # Initializing TextBlock. \n",
        "               get_items=get_imdb, splitter=RandomSplitter(0.1))          # Initializing DataBlock. \n",
        "\n",
        "#@ CREATING LANGUAGE MODEL DATALOADERS: \n",
        "dls_lm = db.dataloaders(path, path=path, bs=128, seq_len=80)              # Initializing Data Loaders. "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "t8zab_Z5fBgA",
        "outputId": "7ae47851-9b1d-42f2-8515-201126117a91"
      },
      "source": [
        "#@ INSPECTING THE BATCHES OF DATA: \n",
        "dls_lm.show_batch(max_n=2)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos a beautiful film about the coming of early silent cinema to xxmaj china . xxup shadow xxup magic deftly combines a love story with the drama of the cultural clash between xxmaj china 's ancient traditions and modern xxmaj western culture in the form of film . xxmaj an amazing first film by xxmaj chinese director xxmaj ann xxmaj hu . xxmaj if i correctly understood xxmaj ms . xxmaj hu 's comments at the 2 xxrep 3 0</td>\n",
              "      <td>a beautiful film about the coming of early silent cinema to xxmaj china . xxup shadow xxup magic deftly combines a love story with the drama of the cultural clash between xxmaj china 's ancient traditions and modern xxmaj western culture in the form of film . xxmaj an amazing first film by xxmaj chinese director xxmaj ann xxmaj hu . xxmaj if i correctly understood xxmaj ms . xxmaj hu 's comments at the 2 xxrep 3 0 xxmaj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is one of the 90 's best thinking person 's romantic movies . xxmaj julie xxmaj delpy turns in one of the decade 's most engaging performances as the xxmaj parisian lass who spends a day with stranger - on - a - train xxmaj ethan xxmaj hawke . xxmaj the dialogue ( and there is oodles of it ) is sometimes meandering and overly precious , but this portrait of two young wannabe - lovers making a romantic ,</td>\n",
              "      <td>one of the 90 's best thinking person 's romantic movies . xxmaj julie xxmaj delpy turns in one of the decade 's most engaging performances as the xxmaj parisian lass who spends a day with stranger - on - a - train xxmaj ethan xxmaj hawke . xxmaj the dialogue ( and there is oodles of it ) is sometimes meandering and overly precious , but this portrait of two young wannabe - lovers making a romantic , intellectual</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oa7FZgFegs1r"
      },
      "source": [
        "**FINETUNING THE LANGAUGE MODEL:**\n",
        "- I will use **Embeddings** to convert the integer word indices into activations that can be used for the neural networks. These embeddings are feed into **Recurrent Neural Network** using and architecture called **AWD-LSTM**. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "K3Qda2V4f9O_",
        "outputId": "001f6f23-a5f3-45a7-ad46-184fbba422b6"
      },
      "source": [
        "#@ INITIALIZING LANGUAGE MODEL LEARNER: \n",
        "learn = language_model_learner(dls_lm, AWD_LSTM, drop_mult=0.3,                 # Using AWD LSTM Architecture. \n",
        "                               metrics=[accuracy, Perplexity()]).to_fp16()      # Initializing LM Learner.                          "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "DwMl0Jl5mZuA",
        "outputId": "859de7e5-7d5f-4dff-cf34-dcc1890894bb"
      },
      "source": [
        "#@ TRAINING EMBEDDINGS WITH RANDOM INITIALIZATION: \n",
        "learn.fit_one_cycle(1, 2e-2)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.006634</td>\n",
              "      <td>3.903991</td>\n",
              "      <td>0.299049</td>\n",
              "      <td>49.600018</td>\n",
              "      <td>21:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlBstN_DoYVY"
      },
      "source": [
        "**SAVING AND LOADING MODELS:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJP-rFdEnDH_",
        "outputId": "e85809a6-da32-49e1-82e8-2b4eec8aaa7e"
      },
      "source": [
        "#@ SAVING MODELS: \n",
        "learn.save(\"/content/gdrive/MyDrive/1Epoch\")                  # Saving the Model. "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('/content/gdrive/MyDrive/1Epoch.pth')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UweY10WKotCV"
      },
      "source": [
        "#@ LOADING MODELS: \n",
        "learn = learn.load(\"/content/gdrive/MyDrive/1Epoch\")          # Loading the Model. "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}