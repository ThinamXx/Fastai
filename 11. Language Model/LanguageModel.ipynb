{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LanguageModel.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAJldAyzepOb"
      },
      "source": [
        "### **INITIALIZATION:**\n",
        "- I use these three lines of code on top of my each notebooks because it will help to prevent any problems while reloading the same project. And the third line of code helps to make visualization within the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO53Px9xdrmE"
      },
      "source": [
        "#@ INITIALIZATION: \n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk8Co18Leyiy"
      },
      "source": [
        "**LIBRARIES AND DEPENDENCIES:**\n",
        "- I have downloaded all the libraries and dependencies required for the project in one particular cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0I-gBJ1ewPX"
      },
      "source": [
        "#@ INSTALLING DEPENDENCIES: UNCOMMENT BELOW: \n",
        "# !pip install -Uqq fastbook\n",
        "# import fastbook\n",
        "# fastbook.setup_book()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l9ySLgOe5QN"
      },
      "source": [
        "#@ DOWNLOADING LIBRARIES AND DEPENDENCIES: \n",
        "from fastbook import *                              # Getting all the Libraries. \n",
        "from fastai.callback.fp16 import *\n",
        "from fastai.text.all import *                       # Getting all the Libraries."
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCAIhIx-fhYh"
      },
      "source": [
        "### **GETTING THE DATA:**\n",
        "- I will use **Human Numbers** dataset here. It contains the first 10000 numbers written out in English. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcPI-9djfVt2",
        "outputId": "f2b79c6c-e1a6-4c95-b594-894eb5d3e22b"
      },
      "source": [
        "#@ GETTING THE DATASET: \n",
        "path = untar_data(URLs.HUMAN_NUMBERS)               # Path to the Dataset. \n",
        "path.ls()                                           # Inspecting the Dataset. "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('/root/.fastai/data/human_numbers/train.txt'),Path('/root/.fastai/data/human_numbers/valid.txt')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxZ4-F9EgOpz",
        "outputId": "aa87d462-1088-46a5-b22d-f42fe3a053c2"
      },
      "source": [
        "#@ JOINING AND INSPECTING THE DATASET: \n",
        "lines = L()                                         # Initializing a List. \n",
        "with open(path/\"train.txt\") as f:                   # Opening the File. \n",
        "    lines += L(*f.readlines())                      # Reading the Lines. \n",
        "with open(path/\"valid.txt\") as f:                   # Opening the File. \n",
        "    lines += L(*f.readlines())                      # Reading the Lines. \n",
        "lines                                               # Inspection. "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#9998) ['one \\n','two \\n','three \\n','four \\n','five \\n','six \\n','seven \\n','eight \\n','nine \\n','ten \\n'...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xUisxqHRk16e",
        "outputId": "798a9995-cba1-4938-dd23-da9f401ef75c"
      },
      "source": [
        "#@ PREPARING THE DATASET: \n",
        "text = \" . \".join([l.strip() for l in lines])       # Preparing the Dataset. \n",
        "text[:100]                                          # Inspection. "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'one . two . three . four . five . six . seven . eight . nine . ten . eleven . twelve . thirteen . fo'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glIUHjTDl69L"
      },
      "source": [
        "**Note:**\n",
        "- I will tokenize the dataset by splitting on spaces. Then I will create a list of unique tokens called vocab for **Numericalization**. Then I will convert the tokens into numbers by looking up in the index of each in the vocab. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNqUHDHEli9w",
        "outputId": "1bd4a701-2bc2-4ffb-b2cc-13e6318d5628"
      },
      "source": [
        "#@ TOKENIZING THE DATASET: \n",
        "tokens = text.split(\" \")                            # Splitting into Tokens. \n",
        "tokens[:10]                                         # Inspecting Tokens. "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['one', '.', 'two', '.', 'three', '.', 'four', '.', 'five', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRnH-KHImgIA",
        "outputId": "d56df5f1-0ca7-40a1-d1c2-70c04f0f8a92"
      },
      "source": [
        "#@ GETTING UNIQUE TOKENS: \n",
        "vocab = L(*tokens).unique()                         # Getting Unique Tokens. \n",
        "vocab                                               # Inspection. "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#30) ['one','.','two','three','four','five','six','seven','eight','nine'...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZotFzTfhnCTI",
        "outputId": "588f666b-beca-4926-b685-fe7d0be91da9"
      },
      "source": [
        "#@ CONVERTING TOKENS INTO NUMBERS: \n",
        "word2idx = {w:i for i,w in enumerate(vocab)}       # Getting Index of Tokens. \n",
        "nums = L(word2idx[i] for i in tokens)              # Converting into Numbers. \n",
        "nums                                               # Inspection.  "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#63095) [0,1,2,1,3,1,4,1,5,1...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_a1MXbJNo0St"
      },
      "source": [
        "### **LANGUAGE MODEL FROM SCRATCH:**\n",
        "- Here I will create a list of every sequence of three words as independent variables and the next word after each sequence as the dependent variable. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7gbp6KZoHpv",
        "outputId": "e1b64886-45e7-4fab-895d-cdc205d6a443"
      },
      "source": [
        "#@ CREATING SEQUENCE OF TOKENS: \n",
        "L((tokens[i:i+3], tokens[i+3]) for i in range(0, len(tokens)-4, 3))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#21031) [(['one', '.', 'two'], '.'),(['.', 'three', '.'], 'four'),(['four', '.', 'five'], '.'),(['.', 'six', '.'], 'seven'),(['seven', '.', 'eight'], '.'),(['.', 'nine', '.'], 'ten'),(['ten', '.', 'eleven'], '.'),(['.', 'twelve', '.'], 'thirteen'),(['thirteen', '.', 'fourteen'], '.'),(['.', 'fifteen', '.'], 'sixteen')...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxKUTFqoqalx",
        "outputId": "4d2720d3-ee31-4a03-e054-32374910f230"
      },
      "source": [
        "#@ CREATING SEQUENCE OF TENSORS FOR NUMERICALIZED VALUES: \n",
        "seqs = L((tensor(nums[i:i+3]), nums[i+3]) for i in range(0, len(nums)-4, 3))   # Creating Sequence.\n",
        "seqs                                                                           # Inspection.  "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#21031) [(tensor([0, 1, 2]), 1),(tensor([1, 3, 1]), 4),(tensor([4, 1, 5]), 1),(tensor([1, 6, 1]), 7),(tensor([7, 1, 8]), 1),(tensor([1, 9, 1]), 10),(tensor([10,  1, 11]), 1),(tensor([ 1, 12,  1]), 13),(tensor([13,  1, 14]), 1),(tensor([ 1, 15,  1]), 16)...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88icbUhQrwew"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}