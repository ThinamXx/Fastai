# **Fastai : CNN Interpretation with CAM**

The [**CNN Interpretation**](https://github.com/ThinamXx/Fastai/blob/main/17.%20CNN%20Interpretation/CNN%20Interpretation.ipynb) notebook presents the implementation of **Class Activation Maps** in model interpretation. Class activation maps give insights into why a model predicted a certain result by showing the areas of images that were most responsible for a given prediction. 

**Note:**
- ðŸ“‘[**CNN Interpretation with CAM**](https://nbviewer.jupyter.org/github/ThinamXx/Fastai/blob/main/17.%20CNN%20Interpretation/CNN%20Interpretation.ipynb)

**Class Activation Map**
- The Class Activation Map uses the output of the last convolutional layer which is just before the average pooling layer together with predictions to give a heatmap visualization of model decision. I have presented the implementation of Defining Hook Function and Decoding Images using Fastai and PyTorch here in the snapshot. 

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%20271.PNG)

**Hook Class**
- I have presented the implementation of Defining Hook Function, Activations, Gradients and Heatmap Visualization using Fastai and PyTorch here in the snapshot.

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%20272a.PNG)
![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%20272b.PNG)
