{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralFoundations.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlHj7lUPa187"
      },
      "source": [
        "**INITIALIZATION**\n",
        "- I use these three lines of code on top of my each notebooks because it will help to prevent any problems while reloading the same project. And the third line of code helps to make visualization within the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taFeJgiOafpU"
      },
      "source": [
        "#@ INITIALIZATION: \n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxH0FCEga_zV"
      },
      "source": [
        "**LIBRARIES AND DEPENDENCIES**\n",
        "- I have downloaded all the libraries and dependencies required for the project in one particular cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4v7GAR2a-IJ"
      },
      "source": [
        "#@ INSTALLING DEPENDENCIES: UNCOMMENT BELOW: \n",
        "# !pip install -Uqq fastbook\n",
        "# import fastbook\n",
        "# fastbook.setup_book()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk9RqKhcbJor"
      },
      "source": [
        "#@ DOWNLOADING LIBRARIES AND DEPENDENCIES: \n",
        "from fastbook import *                                  # Getting all the Libraries. \n",
        "from fastai.callback.fp16 import *"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi-60nNpbv1b"
      },
      "source": [
        "**MODELING NEURON**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4urwjTeBbeHB"
      },
      "source": [
        "#@ MODELING NEURON FROM SCRATCH: UNCOMMENT BELOW: \n",
        "# output = sum([x*w for x,w in zip(inputs, weights)]) + bias          # Adding Weighted Inputs and Bias. \n",
        "# def relu(x): return x if x >= 0 else 0                              # Defining RELU Activation Function. \n",
        "# y[i, j] = sum([a*b for a,b in zip(x[i,:], w[j,:])]) + b[j]          # Initializing Matrix Multiplication. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYCUMtyJgXza",
        "outputId": "f49cf849-d8f0-4aed-debe-7d2208894990"
      },
      "source": [
        "#@ MATRIX MULTIPLICATION FROM SCRATCH: \n",
        "def matmul(a, b):                            # Defining Matrix Multiplication Function. \n",
        "    ar, ac = a.shape                         # Inspecting Shape. \n",
        "    br, bc = b.shape                         # Inspecting Shape. \n",
        "    assert ac == br                          # Asserting Rows and Columns. \n",
        "    c = torch.zeros(ar, bc)                  # Initializing Tensor. \n",
        "    for i in range(ar):                      # Getting Row Indices. \n",
        "        for j in range(bc):                  # Getting Column Indices. \n",
        "            for k in range(ac):              # Getting Inner Sum. \n",
        "                c[i,j] += a[i,k] * b[k,j]    # Getting Matrix Multiplication. \n",
        "    return c\n",
        "\n",
        "#@ IMPLEMENTATION OF MATRIX MULTIPLICATION: \n",
        "m1 = torch.randn(5, 28*28)                   # Initializing Matrix. \n",
        "m2 = torch.randn(784, 10)                    # Initializing Matrix. \n",
        "%time t1 = matmul(m1, m2)                    # Implementation of Matrix Multiplication. \n",
        "%timeit -n 20 t2 = m1@m2                     # Implementation of Matrix Multiplication. "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 685 ms, sys: 0 ns, total: 685 ms\n",
            "Wall time: 767 ms\n",
            "The slowest run took 186.28 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "20 loops, best of 5: 5.49 Âµs per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CY-ny3EzjFXX",
        "outputId": "e810ff70-635b-4315-f769-5c11077e54d7"
      },
      "source": [
        "#@ ELEMENTWISE ARITHMETIC: \n",
        "a = tensor([10., 6, -4])                     # Initializing a Tensor. \n",
        "b = tensor([2., 8, 7])                       # Initializing a Tensor. \n",
        "a + b                                        # Initializing Elementwise Addition. \n",
        "(a<b).all(), (a==b).all()                    # Combining Elementwise Operations. \n",
        "(a + b).sum().item()                         # Converting Tensors. "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29.0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXImxI3msHT0",
        "outputId": "4a389609-beeb-4af9-b151-fbb7e04f7953"
      },
      "source": [
        "#@ MATRIX MULTIPLICATION: SIMPLIFIED: \n",
        "def matmul(a, b):                            # Defining Matrix Multiplication Function. \n",
        "    ar, ac = a.shape                         # Inspecting Shape. \n",
        "    br, bc = b.shape                         # Inspecting Shape. \n",
        "    assert ac == br                          # Asserting Rows and Columns. \n",
        "    c = torch.zeros(ar, bc)                  # Initializing Tensor. \n",
        "    for i in range(ar):                      # Getting Row Indices. \n",
        "        for j in range(bc):                  # Getting Column Indices. \n",
        "            c[i,j] = (a[i] * b[:,j]).sum()\n",
        "    return c\n",
        "\n",
        "#@ IMPLEMENTATION OF MATRIX MULTIPLICATION: \n",
        "m1 = torch.randn(5, 28*28)                   # Initializing Matrix. \n",
        "m2 = torch.randn(784, 10)                    # Initializing Matrix. \n",
        "%time t1 = matmul(m1, m2)                    # Implementation of Matrix Multiplication. "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.36 ms, sys: 0 ns, total: 1.36 ms\n",
            "Wall time: 1.45 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkxhOb3TtTdJ",
        "outputId": "133e4fd0-5abd-48ec-d2ca-c34a2250831b"
      },
      "source": [
        "#@ BROADCASTING VECTOR TO A MATRIX: \n",
        "c = tensor([10., 20, 30])                    # Initializing a Tensor. \n",
        "m = tensor([[1.,2,3], [4,5,6], [7,8,9]])     # Initializing a Tensor. \n",
        "m.shape, c.shape                             # Inspecting Tensors. "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 3]), torch.Size([3]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acHR6ETDu4Uc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "536d555c-c912-4a6c-c1a3-4c1d20d96e54"
      },
      "source": [
        "#@ IMPLEMENTATION OF BROADCASTING: \n",
        "c = tensor([10., 20, 30])                    # Initializing a Tensor. \n",
        "m = tensor([[1.,2,3], [4,5,6], [7,8,9]])     # Initializing a Tensor. \n",
        "c = c.unsqueeze(1)                           # Adding a Unit Dimension. \n",
        "m.shape, c.shape                             # Inspecting Tensors. "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 3]), torch.Size([3, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Elk0-z5X-XnQ",
        "outputId": "a6ae884a-cc56-470b-e0ad-d1421ac88108"
      },
      "source": [
        "#@ MATRIX MULTIPLICATION: SIMPLIFIED: \n",
        "def matmul(a, b):                            # Defining Matrix Multiplication Function. \n",
        "    ar, ac = a.shape                         # Inspecting Shape. \n",
        "    br, bc = b.shape                         # Inspecting Shape. \n",
        "    assert ac == br                          # Asserting Rows and Columns. \n",
        "    c = torch.zeros(ar, bc)                  # Initializing Tensor. \n",
        "    for i in range(ar):                      # Getting Row Indices. \n",
        "        c[i]=(a[i].unsqueeze(-1) * b\n",
        "              ).sum(dim=0)\n",
        "    return c\n",
        "\n",
        "#@ IMPLEMENTATION OF MATRIX MULTIPLICATION: \n",
        "m1 = torch.randn(5, 28*28)                   # Initializing Matrix. \n",
        "m2 = torch.randn(784, 10)                    # Initializing Matrix. \n",
        "%time t1 = matmul(m1, m2)                    # Implementation of Matrix Multiplication. \n",
        "%timeit -n 20 t4 = m1@m2                     # Implementation of Matrix Multiplication. "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 772 Âµs, sys: 148 Âµs, total: 920 Âµs\n",
            "Wall time: 10.7 ms\n",
            "The slowest run took 19.98 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "20 loops, best of 5: 5.42 Âµs per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJwFTSqtC_iY"
      },
      "source": [
        "**EINSTEIN SUMMATION**\n",
        "- Einstein Summation is a compact representation for combining products and sums. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dUPhMn5_laQ",
        "outputId": "d0dce9b9-bfa1-43e6-90d2-1c890cc68756"
      },
      "source": [
        "#@ EINSTEIN SUMMATION IMPLEMENTATION: \n",
        "def matmul(a, b):                            # Defining Matrix Multiplication Function. \n",
        "    return torch.einsum(\"ik,kj->ij\",a,b)     # Implementation of Einstein Summation. \n",
        "%timeit -n 20 t5 = m1@m2                     # Implementation of Matrix Multiplication. "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 6.98 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "20 loops, best of 5: 5.4 Âµs per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKRcwfi0D_72"
      },
      "source": [
        "**FORWARD AND BACKWARD PASSES**\n",
        "- Computing all the gradients of a given loss with respect to its parameters is known as **Backward Pass**. Similarly computing the output of the model on a given input based on the matrix products is known as **Forward Pass**. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdwHrYUQDqyz",
        "outputId": "12655072-7da6-4255-985d-e7b27ae150b0"
      },
      "source": [
        "#@ DEFINING AND INITIALIZING LAYER: \n",
        "def lin(x, w, b): return x @ w + b                  # Defining Linear Layer. \n",
        "x = torch.randn(200, 100)                           # Initializing Random Input Tensors. \n",
        "y = torch.randn(200)                                # Initializing Random Output Tensors. \n",
        "w1 = torch.randn(100, 50)                           # Initializing Random Weights. \n",
        "b1 = torch.zeros(50)                                # Initializing Random Bias. \n",
        "w2 = torch.randn(50, 1)                             # Initializing Random Weights. \n",
        "b2 = torch.zeros(1)                                 # Initializing Random Bias. \n",
        "\n",
        "#@ IMPLEMENTATION OF LINEAR FUNCTION: \n",
        "l1 = lin(x, w1, b1)                                 # Implementation of Function. \n",
        "l1.shape                                            # Inspecting the Shape. "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([200, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msf_-Or4MBFh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}